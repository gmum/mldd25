{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de94b194-3d8f-4adb-9cb5-6b9b0a977c36",
   "metadata": {},
   "source": [
    "![](mldd_diagram_lab5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26cd763",
   "metadata": {},
   "source": [
    "# Introduction to (Deep) Generative Models\n",
    "\n",
    "Generative models are unsupervised ML algorithms, which means that the input data (usually) does not contain labels. Based on the input representation, generative models learn data distribution, which enables generation of novel examples that are similar to those observed in the training.\n",
    "\n",
    "A typical application of generative models is image, text, or compound generation. Several classes of generative models based on neural networks are presented below.\n",
    "\n",
    "1. **Autoencoder** - a model that consists of two networks, an encoder and decoder. The encoder takes the input representation of data and transforms it into a lower-dimensional latent representation (numerical vector). The decoder uses encoded vectors to reconstruct the initial data representation. We can write that $x'=D(E(x))$, and the optimization target is to minimize the difference between the input object $x$ and the reconstructed object $x'$, so the loss function can be $\\mathcal{L}=\\|x-x' \\|_2$ in the case of simple numerical objects as for example images. To make this model generative, the latent space is additionally constrained to follow the Gaussian distribution, i.e. $\\mathcal{L}=\\|x-x' \\|_2 + \\mathcal{L}_{normal}(E(x))$. Then, if we sample a latent vector $z\\sim \\mathcal{N}(0, 1)$ and transform it using the decoder $x'=D(z)$, we will obtain a new generated object.\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/4/4a/VAE_Basic.png)\n",
    "2. **Recurrent neural network (autoregressive modeling)** - a type of neural network in which a partial output is used as the input to the next segment of the network. Recurrent neural networks generate objects by growing object fragments, e.g. texts can be generated word-by-word, and molecules can be created by adding atoms iteratively. The intermediate steps of the generative process are used as the input to the model which decides about the next generation step.\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/5/5f/Gated_Recurrent_Unit.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1e4a73",
   "metadata": {},
   "source": [
    "# How generative models are used to design new drugs\n",
    "\n",
    "There are two ways in which generative models can be applied in drug design. We can generate compounds from scratch, and we call this process *de novo* drug design. The other application is optimization of existing molecules, e.g. during the **lead optimization** stage of drug discovery where our promising compound (so called lead) is modified to increase the activity or optimize other molecular properties (ADMET).\n",
    "\n",
    "Two types of generators can be used to invent new compounds: those based on **SMILES** and those based on **molecular graphs**. We can generate a SMILES sequence, but this representation is prone to produce invalid molecules (SMILES has a strict grammar), on top of other shortcomings discussed when introducing SMILES predictive models. Graph generation seems more reasonable, but this approach also has some downsides:\n",
    "\n",
    "1. Sequential atom-by-atom generation leads to **incorrect intermediate states**. For example, to generate a ring, we need to first generate a long chain of atoms that is closed in the last step. One possible solution to this problem is fragment-based design where we expand molecules by attaching whole structures (e.g. rings) instead of single atoms.\n",
    "2. Molecular graphs are **discrete structures** meaning that atoms and bonds are defined by binary features. We cannot generate partial bonds or mixed atom symbols. Hence, the continuous output of a neural network needs to be converted to a discrete structure, e.g. an adjacency matrix should be rounded to contain only zeros and ones. By discretizing outputs, we lose differentiability of the network, so we can apply the loss function only to the incorrect continuous representation of the molecule before rounding all the numbers. There are some solutions to this problem, e.g. Gumbel Softmax is a technique that allows to preserve the differentiability of the rounding operation. We can also use reinforcement learning that does not require the network to be differentiable (the gradients are calculated in a different way, based on a reward function).\n",
    "\n",
    "Another factor we need to consider when designing drugs is optimization of molecular properties. Not only do we want to generate correct compounds, but also we need these molecules to be synthesizable and possess all the desirable properties. Tp that end, additional learning terms are often included in the generative process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3021a0",
   "metadata": {},
   "source": [
    "# SMILES-based generative model: ReLeaSE\n",
    "\n",
    "Code repo: https://github.com/isayev/ReLeaSE ([Paper](https://www.science.org/doi/epdf/10.1126/sciadv.aap7885))\n",
    "\n",
    "**TL;DR**\n",
    "\n",
    "In this paper, a SMILES generator is implemented. Because SMILES follows certain grammar rules, and it is \"almost\" a context-free grammar, for which there exists a pushdown automaton that accepts this grammar. A stack is needed for the model to remember, e.g., opening of parentheses that denote atom branches or numbers that denote ring closures. By adding a stack to a recurrent neural network (e.g. GRU), we can improve the validity of generated SMILES strings. Additionally, molecular properties of the generated compounds can be optimized by employing a predictive model that calculates the value of a reward function. The reward is calculated when the full SMILES string is generated. Model parameters are corrected using reinforcement learning, and more precisely the REINFORCE algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2da7cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/isayev/ReLeaSE.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58ed6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('ReLeaSE/release')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd9cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c88db64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stackRNN import StackAugmentedRNN\n",
    "from data import GeneratorData\n",
    "\n",
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efaf7216",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "stack_width = 50\n",
    "stack_depth = 10\n",
    "lr = 0.001\n",
    "optimizer_instance = torch.optim.Adadelta\n",
    "layer_type = 'GRU'\n",
    "\n",
    "gen_data_path = 'ReLeaSE/data/logP_labels.csv'\n",
    "gen_data = GeneratorData(training_data_path=gen_data_path, delimiter=',',\n",
    "                         cols_to_read=[1], keep_header=False)\n",
    "\n",
    "my_generator = StackAugmentedRNN(input_size=gen_data.n_characters,\n",
    "                                 hidden_size=hidden_size,\n",
    "                                 output_size=gen_data.n_characters,\n",
    "                                 layer_type=layer_type,\n",
    "                                 n_layers=1, is_bidirectional=True,\n",
    "                                 has_stack=True,\n",
    "                                 stack_width=stack_width,\n",
    "                                 stack_depth=stack_depth,\n",
    "                                 use_cuda=use_cuda,\n",
    "                                 optimizer_instance=optimizer_instance,\n",
    "                                 lr=lr)\n",
    "if use_cuda:\n",
    "    my_generator = my_generator.cuda()\n",
    "\n",
    "losses = my_generator.fit(gen_data, 1000)\n",
    "\n",
    "my_generator.evaluate(gen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3f567ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data_path = 'ReLeaSE/data/chembl_22_clean_1576904_sorted_std_final.smi'\n",
    "tokens = ['<', '>', '#', '%', ')', '(', '+', '-', '/', '.', '1', '0', '3', '2', '5', '4', '7',\n",
    "          '6', '9', '8', '=', 'A', '@', 'C', 'B', 'F', 'I', 'H', 'O', 'N', 'P', 'S', '[', ']',\n",
    "          '\\\\', 'c', 'e', 'i', 'l', 'o', 'n', 'p', 's', 'r', '\\n']\n",
    "gen_data = GeneratorData(training_data_path=gen_data_path, delimiter='\\t', \n",
    "                         cols_to_read=[0], keep_header=True, tokens=tokens)\n",
    "\n",
    "model = StackAugmentedRNN(input_size=gen_data.n_characters, \n",
    "                                     hidden_size=1500,\n",
    "                                     output_size=gen_data.n_characters, \n",
    "                                     layer_type='GRU',\n",
    "                                     n_layers=1, is_bidirectional=False, has_stack=True,\n",
    "                                     stack_width=1500, stack_depth=10, \n",
    "                                     use_cuda=use_cuda)\n",
    "\n",
    "if use_cuda:\n",
    "    model.load_model('ReLeaSE/checkpoints/generator/checkpoint_biggest_rnn')\n",
    "else:\n",
    "    weights = torch.load('ReLeaSE/checkpoints/generator/checkpoint_biggest_rnn', map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cce93bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Smile:  Fc1ccc2ncnc(NN3CCCC3=O)c2c1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x1c9f82b6f40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smiles = model.evaluate(gen_data)[1:-1]\n",
    "\n",
    "print('Random Smile: ', smiles)\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "if mol:\n",
    "    display(mol)\n",
    "else:\n",
    "    print('Invalid SMILES!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e2874d",
   "metadata": {},
   "source": [
    "# Graph-based generative model: JT-VAE\n",
    "\n",
    "Code repo: https://github.com/Bibyutatsu/FastJTNNpy3 ([Paper](https://arxiv.org/pdf/1802.04364.pdf))\n",
    "\n",
    "**TL;DR**\n",
    "\n",
    "JT-VAE is an autoencoder working on molecular graphs. To facilitate compound generation, structural formulas are converted to so-called junction trees, in which rings are transformed into single nodes. This way, instead of a graph, we obtain a tree structure that can be decoded to a compound. The graph encoder is a graph neural network (MPNN), and the tree encoder is a similar architecture, but only passes messages from the root to the leaves. The tree decoder is a recurrent neural network (GRU) that builds a tree in the DFS order. The graph decoder is used to correctly connect atoms after decoding tree nodes - rings have multiple possible attachment points. To optimize molecular properties, we can use Bayesian search of the encoded latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "135cacdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Bibyutatsu/FastJTNNpy3.git\n",
    "\n",
    "import sys\n",
    "use_cuda = False\n",
    "sys.path.append('FastJTNNpy3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b68b8fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch, os\n",
    "\n",
    "if not use_cuda:\n",
    "    for path, dirs, files in os.walk(os.path.abspath(\"FastJTNNpy3\")):\n",
    "        for filename in fnmatch.filter(files, \"*.py\"):\n",
    "            filepath = os.path.join(path, filename)\n",
    "            with open(filepath) as f:\n",
    "                s = f.read()\n",
    "            s = s.replace(\".cuda()\", \"\")\n",
    "            with open(filepath, \"w\") as f:\n",
    "                f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfcd9748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import torch\n",
    "\n",
    "from fast_jtnn import *\n",
    "import rdkit\n",
    "\n",
    "def load_model(vocab, model_path, hidden_size=450, latent_size=56, depthT=20, depthG=3, use_cuda=True):\n",
    "    vocab = [x.strip(\"\\r\\n \") for x in open(vocab)] \n",
    "    vocab = Vocab(vocab)\n",
    "\n",
    "    model = JTNNVAE(vocab, hidden_size, latent_size, depthT, depthG)\n",
    "    if use_cuda:\n",
    "        dict_buffer = torch.load(model_path)\n",
    "    else:\n",
    "        dict_buffer = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(dict_buffer)\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "    return model\n",
    "\n",
    "model = load_model('FastJTNNpy3/data/vocab.txt', 'FastJTNNpy3/fast_molvae/vae_model/model.epoch-19', use_cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "079a0266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:10:55] Explicit valence for atom # 1 C, 5, is greater than permitted\n",
      "[11:10:55] Explicit valence for atom # 1 C, 5, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Smile:  CON1C=CC=CC1C(=O)Nc1ccccc1[N+](=O)[O-]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:10:56] Explicit valence for atom # 1 C, 5, is greater than permitted\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x28ce4e9cb80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.randn(1, 56//2)\n",
    "smiles = model.decode(z, z, False)\n",
    "print('Random Smile: ', smiles)\n",
    "Chem.MolFromSmiles(smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa0d14a-cb74-45f7-89ff-8e8ed22ab01b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between\">\n",
    "    <div style=\"width: 20%; display: inline-block; margin: 20px\">\n",
    "        <img src=\"../../assets/profile2.png\" width=\"100%\">\n",
    "    </div>\n",
    "    <div style=\"width: 60%; display: inline-block; margin: 20px\">\n",
    "        <p><strong>Ester:</strong> Evaluating generative models for small molecules presents unique challenges due to the complexity and diversity of chemical space. Some special problems that emerge include:\n",
    "\n",
    "<ol>\n",
    "    <li>Chemical validity: Ensuring that generated molecules adhere to the rules of chemistry is crucial. This includes checking for correct valency, bond types, and absence of impossible chemical structures.</li>\n",
    "    <li>Drug-likeness: Generated molecules should possess properties that make them suitable candidates for drug development, such as favorable pharmacokinetics and absence of toxic functional groups.</li>\n",
    "    <li>Diversity and novelty: It's important for generative models to produce diverse and novel molecules, rather than generating duplicates or minor variations of existing compounds.</li>\n",
    "    <li>Property optimization: If the generative model is aimed at optimizing specific properties (e.g., potency, solubility), evaluating how well it achieves this goal is essential.</li>\n",
    "    <li>Data efficiency: Generative models for small molecules should be able to generate meaningful molecules even when trained on limited data, as chemical datasets are often smaller than those in other domains.</li>\n",
    "</ol>\n",
    "</p>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886be6de-096b-4964-8c49-391ce4e460c3",
   "metadata": {},
   "source": [
    "# REINVENT\n",
    "\n",
    "Code repo: https://github.com/MarcusOlivecrona/REINVENT ([Paper](https://arxiv.org/pdf/1704.07555.pdf))\n",
    "\n",
    "**TL;DR**\n",
    "\n",
    "The REINVENT model is a recurrent neural network that generates SMILES strings. The model is trained in two steps. The first step is the training of a prior network that learns to generate molecules that are similar to the compounds in the ChEMBL dataset. The next step is the optimization of molecular properties using reinforcement learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e93b9c",
   "metadata": {},
   "source": [
    "**Exercise:** Use the REINVENT model to optimize LogP of the generated compounds. The expected result is a shift of LogP distribution in the generated sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "186a7c35-eb5e-4ca8-b55f-360190da1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from https://github.com/MarcusOlivecrona/REINVENT shared under the MIT license\n",
    "# Small modifications made to make it compatible with the new PyTorch version\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils_reinvent import Variable\n",
    "\n",
    "\n",
    "class MultiGRU(nn.Module):\n",
    "    \"\"\" Implements a three layer GRU cell including an embedding layer\n",
    "       and an output linear layer back to the size of the vocabulary\"\"\"\n",
    "    def __init__(self, voc_size):\n",
    "        super(MultiGRU, self).__init__()\n",
    "        self.embedding = nn.Embedding(voc_size, 128)\n",
    "        self.gru_1 = nn.GRUCell(128, 512)\n",
    "        self.gru_2 = nn.GRUCell(512, 512)\n",
    "        self.gru_3 = nn.GRUCell(512, 512)\n",
    "        self.linear = nn.Linear(512, voc_size)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        x = self.embedding(x)\n",
    "        h_out = Variable(torch.zeros(h.size()))\n",
    "        x = h_out[0] = self.gru_1(x, h[0])\n",
    "        x = h_out[1] = self.gru_2(x, h[1])\n",
    "        x = h_out[2] = self.gru_3(x, h[2])\n",
    "        x = self.linear(x)\n",
    "        return x, h_out\n",
    "\n",
    "    def init_h(self, batch_size):\n",
    "        # Initial cell state is zero\n",
    "        return Variable(torch.zeros(3, batch_size, 512))\n",
    "\n",
    "class RNN():\n",
    "    \"\"\"Implements the Prior and Agent RNN. Needs a Vocabulary instance in\n",
    "    order to determine size of the vocabulary and index of the END token\"\"\"\n",
    "    def __init__(self, voc):\n",
    "        self.rnn = MultiGRU(voc.vocab_size)\n",
    "        if torch.cuda.is_available():\n",
    "            self.rnn.cuda()\n",
    "        self.voc = voc\n",
    "\n",
    "    def likelihood(self, target):\n",
    "        \"\"\"\n",
    "            Retrieves the likelihood of a given sequence\n",
    "\n",
    "            Args:\n",
    "                target: (batch_size * sequence_lenght) A batch of sequences\n",
    "\n",
    "            Outputs:\n",
    "                log_probs : (batch_size) Log likelihood for each example*\n",
    "                entropy: (batch_size) The entropies for the sequences. Not\n",
    "                                      currently used.\n",
    "        \"\"\"\n",
    "        batch_size, seq_length = target.size()\n",
    "        start_token = Variable(torch.zeros(batch_size, 1).long())\n",
    "        start_token[:] = self.voc.vocab['GO']\n",
    "        x = torch.cat((start_token, target[:, :-1]), 1)\n",
    "        h = self.rnn.init_h(batch_size)\n",
    "\n",
    "        log_probs = Variable(torch.zeros(batch_size))\n",
    "        entropy = Variable(torch.zeros(batch_size))\n",
    "        for step in range(seq_length):\n",
    "            logits, h = self.rnn(x[:, step], h)\n",
    "            log_prob = F.log_softmax(logits)\n",
    "            prob = F.softmax(logits)\n",
    "            log_probs += NLLLoss(log_prob, target[:, step])\n",
    "            entropy += -torch.sum((log_prob * prob), 1)\n",
    "        return log_probs, entropy\n",
    "\n",
    "    def sample(self, batch_size, max_length=140):\n",
    "        \"\"\"\n",
    "            Sample a batch of sequences\n",
    "\n",
    "            Args:\n",
    "                batch_size : Number of sequences to sample \n",
    "                max_length:  Maximum length of the sequences\n",
    "\n",
    "            Outputs:\n",
    "            seqs: (batch_size, seq_length) The sampled sequences.\n",
    "            log_probs : (batch_size) Log likelihood for each sequence.\n",
    "            entropy: (batch_size) The entropies for the sequences. Not\n",
    "                                    currently used.\n",
    "        \"\"\"\n",
    "        start_token = Variable(torch.zeros(batch_size).long())\n",
    "        start_token[:] = self.voc.vocab['GO']\n",
    "        h = self.rnn.init_h(batch_size)\n",
    "        x = start_token\n",
    "\n",
    "        sequences = []\n",
    "        log_probs = Variable(torch.zeros(batch_size))\n",
    "        finished = torch.zeros(batch_size).byte()\n",
    "        entropy = Variable(torch.zeros(batch_size))\n",
    "        if torch.cuda.is_available():\n",
    "            finished = finished.cuda()\n",
    "\n",
    "        for step in range(max_length):\n",
    "            logits, h = self.rnn(x, h)\n",
    "            prob = F.softmax(logits)\n",
    "            log_prob = F.log_softmax(logits)\n",
    "            x = torch.multinomial(prob, num_samples=1).view(-1)\n",
    "            sequences.append(x.view(-1, 1))\n",
    "            log_probs +=  NLLLoss(log_prob, x)\n",
    "            entropy += -torch.sum((log_prob * prob), 1)\n",
    "\n",
    "            x = Variable(x.data)\n",
    "            EOS_sampled = (x == self.voc.vocab['EOS']).data\n",
    "            finished = torch.ge(finished + EOS_sampled, 1)\n",
    "            if torch.prod(finished) == 1: break\n",
    "\n",
    "        sequences = torch.cat(sequences, 1)\n",
    "        return sequences.data, log_probs, entropy\n",
    "\n",
    "def NLLLoss(inputs, targets):\n",
    "    \"\"\"\n",
    "        Custom Negative Log Likelihood loss that returns loss per example,\n",
    "        rather than for the entire batch.\n",
    "\n",
    "        Args:\n",
    "            inputs : (batch_size, num_classes) *Log probabilities of each class*\n",
    "            targets: (batch_size) *Target class index*\n",
    "\n",
    "        Outputs:\n",
    "            loss : (batch_size) *Loss for each example*\n",
    "    \"\"\"\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        target_expanded = torch.zeros(inputs.size()).cuda()\n",
    "    else:\n",
    "        target_expanded = torch.zeros(inputs.size())\n",
    "\n",
    "    target_expanded.scatter_(1, targets.contiguous().view(-1, 1).data, 1.0)\n",
    "    loss = Variable(target_expanded) * inputs\n",
    "    loss = torch.sum(loss, 1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a93093-362f-4e7c-a59f-cfdd56894970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "from data_structs import Vocabulary, Experience\n",
    "from utils_reinvent import Variable, seq_to_smiles, fraction_valid_smiles, unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "534a122a-d6e9-495c-85db-90cf69b8d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fixed_checkpoint(filename):\n",
    "    if torch.cuda.is_available():\n",
    "        checkpoint = torch.load(filename)\n",
    "    else:\n",
    "        checkpoint = torch.load(filename, map_location=lambda storage, loc: storage)\n",
    "    for i in [1, 2, 3]:\n",
    "        for weight_name in ['ih', 'hh']:\n",
    "            checkpoint[f'gru_{i}.bias_{weight_name}'] = checkpoint[f'gru_{i}.bias_{weight_name}'].flatten()\n",
    "    return checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63e81ff6-7c25-472a-ad16-039361151b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_checkpoint = load_fixed_checkpoint('Prior.ckpt')\n",
    "agent_checkpoint = load_fixed_checkpoint('Prior.ckpt')\n",
    "save_dir=None\n",
    "learning_rate=0.0005\n",
    "batch_size=64\n",
    "n_steps=3000\n",
    "num_processes=0\n",
    "sigma=60\n",
    "experience_replay=0\n",
    "\n",
    "voc = Vocabulary(init_from_file=\"Voc\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "Prior = RNN(voc)\n",
    "Agent = RNN(voc)\n",
    "\n",
    "# By default restore Agent to same model as Prior, but can restore from already trained Agent too.\n",
    "# Saved models are partially on the GPU, but if we dont have cuda enabled we can remap these\n",
    "# to the CPU.\n",
    "Prior.rnn.load_state_dict(prior_checkpoint)\n",
    "Agent.rnn.load_state_dict(agent_checkpoint)\n",
    "\n",
    "# We dont need gradients with respect to Prior\n",
    "for param in Prior.rnn.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(Agent.rnn.parameters(), lr=0.0005)\n",
    "\n",
    "# Scoring_function\n",
    "class Singleprocessing():\n",
    "    \"\"\"Adds an option to not spawn new processes for the scoring functions, but rather\n",
    "       run them in the main process.\"\"\"\n",
    "    def __init__(self, scoring_function=None):\n",
    "        self.scoring_function = scoring_function\n",
    "    def __call__(self, smiles):\n",
    "        scores = [self.scoring_function(smile) for smile in smiles]\n",
    "        return np.array(scores, dtype=np.float32)\n",
    "\n",
    "def scoring_function(smiles):\n",
    "    return ...  # TODO: implement your scoring function\n",
    "        \n",
    "scoring_function = Singleprocessing(scoring_function=scoring_function)\n",
    "\n",
    "# For policy based RL, we normally train on-policy and correct for the fact that more likely actions\n",
    "# occur more often (which means the agent can get biased towards them). Using experience replay is\n",
    "# therefor not as theoretically sound as it is for value based RL, but it seems to work well.\n",
    "experience = Experience(voc)\n",
    "\n",
    "print(\"Model initialized, starting training...\")\n",
    "if not save_dir:\n",
    "    save_dir = 'results/run_' + time.strftime(\"%Y-%m-%d-%H_%M_%S\", time.localtime())\n",
    "os.makedirs(save_dir)\n",
    "\n",
    "for step in range(n_steps):\n",
    "\n",
    "    # Sample from Agent\n",
    "    seqs, agent_likelihood, entropy = Agent.sample(batch_size)\n",
    "\n",
    "    # Remove duplicates, ie only consider unique seqs\n",
    "    unique_idxs = unique(seqs)\n",
    "    seqs = seqs[unique_idxs]\n",
    "    agent_likelihood = agent_likelihood[unique_idxs]\n",
    "    entropy = entropy[unique_idxs]\n",
    "\n",
    "    # Get prior likelihood and score\n",
    "    prior_likelihood, _ = Prior.likelihood(Variable(seqs))\n",
    "    smiles = seq_to_smiles(seqs, voc)\n",
    "    score = scoring_function(smiles)\n",
    "\n",
    "    # Calculate augmented likelihood\n",
    "    augmented_likelihood = prior_likelihood + sigma * Variable(score)\n",
    "    loss = torch.pow((augmented_likelihood - agent_likelihood), 2)\n",
    "\n",
    "    # Experience Replay\n",
    "    # First sample\n",
    "    if experience_replay and len(experience)>4:\n",
    "        exp_seqs, exp_score, exp_prior_likelihood = experience.sample(4)\n",
    "        exp_agent_likelihood, exp_entropy = Agent.likelihood(exp_seqs.long())\n",
    "        exp_augmented_likelihood = exp_prior_likelihood + sigma * exp_score\n",
    "        exp_loss = torch.pow((Variable(exp_augmented_likelihood) - exp_agent_likelihood), 2)\n",
    "        loss = torch.cat((loss, exp_loss), 0)\n",
    "        agent_likelihood = torch.cat((agent_likelihood, exp_agent_likelihood), 0)\n",
    "\n",
    "    # Then add new experience\n",
    "    prior_likelihood = prior_likelihood.data.cpu().numpy()\n",
    "    new_experience = zip(smiles, score, prior_likelihood)\n",
    "    experience.add_experience(new_experience)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = loss.mean()\n",
    "\n",
    "    # Add regularizer that penalizes high likelihood for the entire sequence\n",
    "    loss_p = - (1 / agent_likelihood).mean()\n",
    "    loss += 5 * 1e3 * loss_p\n",
    "\n",
    "    # Calculate gradients and make an update to the network weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Convert to numpy arrays so that we can print them\n",
    "    augmented_likelihood = augmented_likelihood.data.cpu().numpy()\n",
    "    agent_likelihood = agent_likelihood.data.cpu().numpy()\n",
    "\n",
    "    # Print some information for this step\n",
    "    time_elapsed = (time.time() - start_time) / 3600\n",
    "    time_left = (time_elapsed * ((n_steps - step) / (step + 1)))\n",
    "    print(\"\\n       Step {}   Fraction valid SMILES: {:4.1f}  Time elapsed: {:.2f}h Time left: {:.2f}h\".format(\n",
    "          step, fraction_valid_smiles(smiles) * 100, time_elapsed, time_left))\n",
    "    print(\"  Agent    Prior   Target   Score             SMILES\")\n",
    "    for i in range(10):\n",
    "        print(\" {:6.2f}   {:6.2f}  {:6.2f}  {:6.2f}     {}\".format(agent_likelihood[i],\n",
    "                                                                   prior_likelihood[i],\n",
    "                                                                   augmented_likelihood[i],\n",
    "                                                                   score[i],\n",
    "                                                                   smiles[i]))\n",
    "\n",
    "    experience.print_memory(os.path.join(save_dir, \"memory\"))\n",
    "    torch.save(Agent.rnn.state_dict(), os.path.join(save_dir, 'Agent.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbe72a9e-417d-43ff-9543-2b389e3f75d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "seqs, agent_likelihood, entropy = Agent.sample(256)\n",
    "smiles = seq_to_smiles(seqs, voc)\n",
    "score = scoring_function(smiles)\n",
    "\n",
    "seqs, agent_likelihood, entropy = Prior.sample(256)\n",
    "smiles_prior = seq_to_smiles(seqs, voc)\n",
    "score_prior = scoring_function(smiles_prior)\n",
    "\n",
    "df = pd.DataFrame({'smiles': smiles_prior + smiles, 'LogP': list(score_prior) + list(score), 'model': ['pre'] * len(smiles_prior) + ['post'] * len(smiles)})\n",
    "df.to_csv('output.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66ed63cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=df, x='LogP', hue='model', fill=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
